<!-- Generated by documentation.js. Update this documentation by updating the source code. -->

## cachify-wrapper

Wraps a function with a caching layer

**Parameters**

-   `fn` **[Function][1]** - source of data
-   `storage` **[Object][2]** cache storage that implements CacheStorage<K, V> interface [must provide get(key) and set(key, value, expired) methods] (optional, default `InMemoryStorage`)
-   `options` **[Object][2]?**
    -   `options.expire` **[Number][3]** cached data ttl (TimeToLive) [in milliseconds] (optional, default `1000`)
    -   `options.deviation` **[Number][3]** ttl deviation (prevents simultaneous keys deletions) (optional, default `options.expire.ttl/100`)
    -   `options.stale` **[Number][3]** additional ttl for stale data (optional, default `0`)
    -   `options.ttl` **[Number][3]** forced ttl for data (useful in case on multiply service with different expire) (optional, default `options.expire+options.stale`)
    -   `options.lock` **[Number][3]** lock timeout (prevents simultaneous concurrent invoke of `fn` at initial period) (optional, default `1000`)
    -   `options.hasher` **[Function][1]** creates key for KV-storage by `fn` arguments (optional, default `JSON.stringify`)
    -   `options.storage.timeout` **[Number][3]?** max cache response time before considering it as disabled, and invoking actual request to source (optional, default `Infinity`)
    -   `options.storage.strategy` invoke and return strategy for `storage` (optional, default `Strategies.ASYNC`). Can be Strategies.SYNC, Strategies.ASYNC, Strategies.CALLBACK
    -   `options.source.timeout` **[Number][3]?** max fn response time before considering it as failed (optional, default `Infinity`)
    -   `options.source.strategy` invoke and return strategy for `fn` (optional, default `Strategies.ASYNC`)
    -   `options.source.latency` **[Number][3]** expected source response time. With `options.retries` affect on awaiting for duplicate requests for first request result (optional, default `options.lock.timeout`)
    -   `options.retries` **[Number][3]** number of passes before new actual request (optional, default `(options.lock.timeout/options.latency)+1`)
    -   `options.debug` **[Boolean][4]?** debug logs

**Examples**

```javascript
const wrapper = require('cachify-wrapper').default;
const redis = require('redis');
class RedisCache {
 constructor() {
  this.client = redis.createClient();
 }
 set (key, value, expire) {
  return new Promise((resolve, reject) => this.client.set(key, JSON.stringify(value), (error, value) => error ? reject(error) :
    expire ? this.client.pexpire(key, expire, (error) => error ? reject(error) : resolve(value)) :
    resolve(value)));
 }
 get (key) {
  return new Promise((resolve, reject) => this.client.get(key, (error, value) => error ? reject(error) : resolve(JSON.parse(value))));
 }
}
const cache = new RedisCache();
const sourceFunc = (a) => new Promise((resolve) => setTimeout(() => resolve(a * 2), 250));
const options = {expire: 500, lock: 100, retries: 1, source: {latency: 100}};
const cached = wrapper(sourceFunc, cache, options);
cached(123).then((payload) => console.dir(payload, {colors: true, depth: null})); // Invoke new request
setTimeout(() => cached(123).then((payload) => console.dir(payload, {colors: true, depth: null})), 200); // Will get cached result
setTimeout(() => cached(123).then((payload) => console.dir(payload, {colors: true, depth: null})), 50); // Will invoke new actual request (because of low retries & latency options it can't wait for first invoke cache)
```

Returns **[Function][1]** wrapped function

[1]: https://developer.mozilla.org/docs/Web/JavaScript/Reference/Statements/function

[2]: https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Object

[3]: https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Number

[4]: https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Boolean
